Prompt Caching/Batching Scaffold
================================

- Purpose: document usage of the caching utilities in `selfcheckgpt/prompt_utils.py` once wired into prompt-based scorers.
- To do for the assigned agent:
  - Add opt-in flags/kwargs on prompt scorers to enable caching/batching.
  - Define cache key fields (prompt, model, client type, sample id, etc.).
  - Add example commands here showing cache priming and cache hits.
